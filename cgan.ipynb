{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0945d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51532392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7abca31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры \n",
    "IMAGE_SIZE = 64\n",
    "BATCH = 128\n",
    "LATENT_DIM = 256\n",
    "NUM_EPOCHS_GAN = 100\n",
    "LR = 2e-4\n",
    "SAMPLE_PER_CLASS = 4\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1239299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к данным\n",
    "DATA_ROOT = Path(\"data/animals\")\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53ae0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pin_memory = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Трансформы и DataLoader \n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=str(DATA_ROOT), transform=tf)\n",
    "\n",
    "if len(dataset) == 0:\n",
    "    raise RuntimeError(f\"No images found in {DATA_ROOT}. Проверьте, что данные распакованы в data/animals/<class>/*.jpg\")\n",
    "\n",
    "class_names = dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Found classes:\", NUM_CLASSES)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=pin_memory, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da886f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Утилиты \n",
    "def save_sample_grid(tensor, path, nrow=8):\n",
    "    tensor = tensor.clamp(-1, 1)\n",
    "    save_image((tensor + 1) / 2, path, nrow=nrow)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def one_hot(labels, C):\n",
    "    return torch.zeros(labels.size(0), C, device=labels.device).scatter_(1, labels.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional GAN модели \n",
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, n_classes, embed_dim=128):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        self.embed = nn.Embedding(n_classes, embed_dim)\n",
    "        self.fc_gamma = nn.Linear(embed_dim, num_features)\n",
    "        self.fc_beta = nn.Linear(embed_dim, num_features)\n",
    "        nn.init.zeros_(self.fc_gamma.weight); nn.init.zeros_(self.fc_gamma.bias)\n",
    "        nn.init.zeros_(self.fc_beta.weight);  nn.init.zeros_(self.fc_beta.bias)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        out = self.bn(x)\n",
    "        e = self.embed(labels)\n",
    "        gamma = self.fc_gamma(e).unsqueeze(2).unsqueeze(3)\n",
    "        beta  = self.fc_beta(e).unsqueeze(2).unsqueeze(3)\n",
    "        return out * (1 + gamma) + beta\n",
    "\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "class CGenerator(nn.Module):\n",
    "    def __init__(self, z_dim, n_classes, img_channels=3, base=64, embed_dim=128):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.label_emb = nn.Embedding(n_classes, embed_dim)\n",
    "\n",
    "        input_dim = z_dim + embed_dim\n",
    "        self.fc = nn.Linear(input_dim, base*8*4*4)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(base*8, base*4, 4, 2, 1, bias=False)\n",
    "        self.cbn1 = ConditionalBatchNorm2d(base*4, n_classes, embed_dim)\n",
    "        self.deconv2 = nn.ConvTranspose2d(base*4, base*2, 4, 2, 1, bias=False)\n",
    "        self.cbn2 = ConditionalBatchNorm2d(base*2, n_classes, embed_dim)\n",
    "        self.deconv3 = nn.ConvTranspose2d(base*2, base, 4, 2, 1, bias=False)\n",
    "        self.cbn3 = ConditionalBatchNorm2d(base, n_classes, embed_dim)\n",
    "\n",
    "        self.final = nn.ConvTranspose2d(base, img_channels, 4, 2, 1)\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        l = self.label_emb(labels)\n",
    "        x = torch.cat([z, l], dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.base*8, 4, 4)\n",
    "\n",
    "        x = F.relu(self.cbn1(self.deconv1(x), labels))\n",
    "        x = F.relu(self.cbn2(self.deconv2(x), labels))\n",
    "        x = F.relu(self.cbn3(self.deconv3(x), labels))\n",
    "        x = torch.tanh(self.final(x))\n",
    "        return x\n",
    "\n",
    "class CDiscriminator(nn.Module):\n",
    "    def __init__(self, n_classes, img_channels=3, base=64):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(img_channels, base, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(base, base*2, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(base*2, base*4, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(base*4, base*8, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc_adv = spectral_norm(nn.Linear(base*8, 1))\n",
    "        self.fc_cls = spectral_norm(nn.Linear(base*8, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.features(x).view(x.size(0), -1)\n",
    "        adv_out = self.fc_adv(feat).squeeze(1)\n",
    "        cls_out = self.fc_cls(feat)\n",
    "        return adv_out, cls_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "896193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_hinge_loss(real_logits, fake_logits):\n",
    "    loss_real = torch.mean(F.relu(1.0 - real_logits))\n",
    "    loss_fake = torch.mean(F.relu(1.0 + fake_logits))\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "def g_hinge_loss(fake_logits):\n",
    "    return -torch.mean(fake_logits)\n",
    "\n",
    "def r1_penalty(real_img, real_adv):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=real_adv.sum(),\n",
    "        inputs=real_img,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    return (grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2).mean()\n",
    "\n",
    "def add_instance_noise(x, std=0.05):\n",
    "    if std > 0:\n",
    "        noise = torch.randn_like(x) * std\n",
    "        return x + noise\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d6a73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Инициализация моделей, оптимизаторы \n",
    "G = CGenerator(LATENT_DIM, NUM_CLASSES).to(device)\n",
    "D = CDiscriminator(NUM_CLASSES).to(device)\n",
    "\n",
    "optG = torch.optim.Adam(G.parameters(), lr=5e-5, betas=(0.5,0.999))\n",
    "optD = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "fixed_z = torch.randn(NUM_CLASSES * 8, LATENT_DIM, device=device)\n",
    "fixed_labels = torch.tensor([i for i in range(NUM_CLASSES) for _ in range(8)], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83be7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировочный цикл\n",
    "def train_cgan(loader, epochs=100, noise_std=0.05, out_dir=OUT_DIR):\n",
    "    G.train(); D.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(loader, desc=f\"cGAN epoch {epoch+1}/{epochs}\")\n",
    "        for imgs, labs in pbar:\n",
    "            imgs = imgs.to(device); labs = labs.to(device)\n",
    "            bs = imgs.size(0)\n",
    "\n",
    "            # Discriminator step\n",
    "            for _ in range(2):  # d_steps=2\n",
    "                z = torch.randn(bs, LATENT_DIM, device=device)\n",
    "                fake = G(z, labs)\n",
    "                imgs.requires_grad_(True) \n",
    "                real_adv, real_cls = D(add_instance_noise(imgs, noise_std))\n",
    "                fake_adv, fake_cls = D(add_instance_noise(fake.detach(), noise_std))\n",
    "\n",
    "                lossD_adv = d_hinge_loss(real_adv, fake_adv)\n",
    "                lossD_cls = cls_loss(real_cls, labs)\n",
    "                lossD_r1 = r1_penalty(imgs, real_adv) * 10.0  \n",
    "                lossD = lossD_adv + lossD_cls + lossD_r1\n",
    "\n",
    "                optD.zero_grad(); lossD.backward(); optD.step()\n",
    "\n",
    "\n",
    "            # Generator step\n",
    "            for _ in range(1):  \n",
    "                z = torch.randn(bs, LATENT_DIM, device=device)\n",
    "                fake = G(z, labs)\n",
    "                fake_adv, fake_cls = D(add_instance_noise(fake, noise_std))\n",
    "                lossG_adv = g_hinge_loss(fake_adv)\n",
    "                lossG_cls = cls_loss(fake_cls, labs)\n",
    "                lossG = lossG_adv + lossG_cls\n",
    "\n",
    "                optG.zero_grad(); lossG.backward(); optG.step()\n",
    "\n",
    "            pbar.set_postfix({'lossD': float(lossD.item()), 'lossG': float(lossG.item())})\n",
    "\n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            # Fixed noise (consistency)\n",
    "            sample_fixed = G(fixed_z, fixed_labels).cpu()\n",
    "            save_sample_grid(sample_fixed, f\"{out_dir}/cgan_epoch{epoch+1}_fixed.png\", nrow=8)\n",
    "\n",
    "            # Random noise (diversity check)\n",
    "            z = torch.randn(NUM_CLASSES * 8, LATENT_DIM, device=device)\n",
    "            labels = torch.tensor([i for i in range(NUM_CLASSES) for _ in range(8)], device=device)\n",
    "            sample_rand = G(z, labels).cpu()\n",
    "            save_sample_grid(sample_rand, f\"{out_dir}/cgan_epoch{epoch+1}_random.png\", nrow=8)\n",
    "        G.train()\n",
    "\n",
    "    torch.save(G.state_dict(), f\"{out_dir}/cgan_G.pth\")\n",
    "    torch.save(D.state_dict(), f\"{out_dir}/cgan_D.pth\")\n",
    "    print(\"Saved models to\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de13a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация по имени класса \n",
    "def class_name_to_index(name):\n",
    "    lowered = [c.lower() for c in class_names]\n",
    "    name_l = name.lower()\n",
    "    if name_l in lowered:\n",
    "        return lowered.index(name_l)\n",
    "    for i, c in enumerate(lowered):\n",
    "        if c.startswith(name_l) or name_l in c:\n",
    "            return i\n",
    "    raise ValueError(\"class not found\")\n",
    "\n",
    "def generate_cgan(breed_name, n=4, save_path=None):\n",
    "    idx = class_name_to_index(breed_name)\n",
    "    z = torch.randn(n, LATENT_DIM, device=device)\n",
    "    labels = torch.tensor([idx] * n, device=device)\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs = G(z, labels).cpu()\n",
    "    if save_path:\n",
    "        save_sample_grid(imgs, save_path, nrow=n)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e25e41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cGAN epoch 1/100: 100%|██████████| 105/105 [00:22<00:00,  4.59it/s, lossD=2.49, lossG=2.2]   \n",
      "cGAN epoch 2/100: 100%|██████████| 105/105 [00:23<00:00,  4.55it/s, lossD=2.18, lossG=1.34]  \n",
      "cGAN epoch 3/100: 100%|██████████| 105/105 [00:21<00:00,  4.79it/s, lossD=2.3, lossG=0.543]   \n",
      "cGAN epoch 4/100: 100%|██████████| 105/105 [00:23<00:00,  4.52it/s, lossD=2.17, lossG=1.21]  \n",
      "cGAN epoch 5/100: 100%|██████████| 105/105 [00:23<00:00,  4.38it/s, lossD=2.26, lossG=1.2]   \n",
      "cGAN epoch 6/100: 100%|██████████| 105/105 [00:21<00:00,  4.80it/s, lossD=2.45, lossG=1.41]   \n",
      "cGAN epoch 7/100: 100%|██████████| 105/105 [00:35<00:00,  2.99it/s, lossD=2.04, lossG=1.3]   \n",
      "cGAN epoch 8/100: 100%|██████████| 105/105 [00:47<00:00,  2.20it/s, lossD=2.23, lossG=1.39]  \n",
      "cGAN epoch 9/100: 100%|██████████| 105/105 [00:27<00:00,  3.86it/s, lossD=1.96, lossG=1.04]  \n",
      "cGAN epoch 10/100: 100%|██████████| 105/105 [00:44<00:00,  2.34it/s, lossD=2.29, lossG=0.144]  \n",
      "cGAN epoch 11/100: 100%|██████████| 105/105 [00:40<00:00,  2.57it/s, lossD=2.38, lossG=0.87]   \n",
      "cGAN epoch 12/100: 100%|██████████| 105/105 [00:39<00:00,  2.67it/s, lossD=2.12, lossG=1.33]   \n",
      "cGAN epoch 13/100: 100%|██████████| 105/105 [00:49<00:00,  2.13it/s, lossD=2.11, lossG=0.42]  \n",
      "cGAN epoch 14/100: 100%|██████████| 105/105 [00:37<00:00,  2.83it/s, lossD=2.32, lossG=1.33]  \n",
      "cGAN epoch 15/100: 100%|██████████| 105/105 [00:26<00:00,  4.00it/s, lossD=2.17, lossG=0.748]  \n",
      "cGAN epoch 16/100: 100%|██████████| 105/105 [00:31<00:00,  3.29it/s, lossD=1.93, lossG=0.576]\n",
      "cGAN epoch 17/100: 100%|██████████| 105/105 [00:43<00:00,  2.40it/s, lossD=2.06, lossG=1.28]    \n",
      "cGAN epoch 18/100: 100%|██████████| 105/105 [00:50<00:00,  2.08it/s, lossD=2.2, lossG=1.44]   \n",
      "cGAN epoch 19/100: 100%|██████████| 105/105 [00:41<00:00,  2.52it/s, lossD=2.22, lossG=0.594] \n",
      "cGAN epoch 20/100: 100%|██████████| 105/105 [00:49<00:00,  2.13it/s, lossD=2.05, lossG=0.0468] \n",
      "cGAN epoch 21/100: 100%|██████████| 105/105 [00:42<00:00,  2.49it/s, lossD=2.12, lossG=-0.652]\n",
      "cGAN epoch 22/100: 100%|██████████| 105/105 [00:41<00:00,  2.56it/s, lossD=2.18, lossG=1.25]  \n",
      "cGAN epoch 23/100: 100%|██████████| 105/105 [00:41<00:00,  2.55it/s, lossD=2.24, lossG=1.16]  \n",
      "cGAN epoch 24/100: 100%|██████████| 105/105 [00:39<00:00,  2.68it/s, lossD=2.24, lossG=1.08]  \n",
      "cGAN epoch 25/100: 100%|██████████| 105/105 [00:43<00:00,  2.41it/s, lossD=2.05, lossG=0.93] \n",
      "cGAN epoch 26/100: 100%|██████████| 105/105 [00:38<00:00,  2.74it/s, lossD=2.22, lossG=0.683] \n",
      "cGAN epoch 27/100: 100%|██████████| 105/105 [00:22<00:00,  4.71it/s, lossD=2.11, lossG=1.12] \n",
      "cGAN epoch 28/100: 100%|██████████| 105/105 [00:20<00:00,  5.13it/s, lossD=2.21, lossG=1.5]   \n",
      "cGAN epoch 29/100: 100%|██████████| 105/105 [00:21<00:00,  4.83it/s, lossD=2.16, lossG=0.646]\n",
      "cGAN epoch 30/100: 100%|██████████| 105/105 [00:23<00:00,  4.49it/s, lossD=2.14, lossG=0.794] \n",
      "cGAN epoch 31/100: 100%|██████████| 105/105 [00:20<00:00,  5.21it/s, lossD=2.24, lossG=1.21] \n",
      "cGAN epoch 32/100: 100%|██████████| 105/105 [00:27<00:00,  3.79it/s, lossD=1.95, lossG=0.57]  \n",
      "cGAN epoch 33/100: 100%|██████████| 105/105 [00:36<00:00,  2.85it/s, lossD=2.26, lossG=0.939] \n",
      "cGAN epoch 34/100: 100%|██████████| 105/105 [00:27<00:00,  3.78it/s, lossD=2.37, lossG=1.39]   \n",
      "cGAN epoch 35/100: 100%|██████████| 105/105 [00:22<00:00,  4.66it/s, lossD=2.15, lossG=0.302] \n",
      "cGAN epoch 36/100: 100%|██████████| 105/105 [00:22<00:00,  4.68it/s, lossD=2.02, lossG=-0.58] \n",
      "cGAN epoch 37/100: 100%|██████████| 105/105 [00:20<00:00,  5.06it/s, lossD=2.23, lossG=0.902] \n",
      "cGAN epoch 38/100: 100%|██████████| 105/105 [00:21<00:00,  4.84it/s, lossD=2.02, lossG=0.894] \n",
      "cGAN epoch 39/100: 100%|██████████| 105/105 [00:23<00:00,  4.55it/s, lossD=2.2, lossG=0.698]  \n",
      "cGAN epoch 40/100: 100%|██████████| 105/105 [00:21<00:00,  4.97it/s, lossD=2.14, lossG=1.1]   \n",
      "cGAN epoch 41/100: 100%|██████████| 105/105 [00:25<00:00,  4.17it/s, lossD=2.16, lossG=0.876]  \n",
      "cGAN epoch 42/100: 100%|██████████| 105/105 [00:32<00:00,  3.25it/s, lossD=2.3, lossG=0.871]   \n",
      "cGAN epoch 43/100: 100%|██████████| 105/105 [00:39<00:00,  2.64it/s, lossD=2.24, lossG=0.82]  \n",
      "cGAN epoch 44/100: 100%|██████████| 105/105 [00:29<00:00,  3.57it/s, lossD=2.1, lossG=1.43]    \n",
      "cGAN epoch 45/100: 100%|██████████| 105/105 [00:22<00:00,  4.62it/s, lossD=2.04, lossG=0.723] \n",
      "cGAN epoch 46/100: 100%|██████████| 105/105 [00:20<00:00,  5.13it/s, lossD=2.23, lossG=0.0759] \n",
      "cGAN epoch 47/100: 100%|██████████| 105/105 [00:21<00:00,  4.90it/s, lossD=2.1, lossG=0.939]  \n",
      "cGAN epoch 48/100: 100%|██████████| 105/105 [00:22<00:00,  4.63it/s, lossD=2.08, lossG=1.24]  \n",
      "cGAN epoch 49/100: 100%|██████████| 105/105 [00:20<00:00,  5.18it/s, lossD=1.84, lossG=-0.0231]\n",
      "cGAN epoch 50/100: 100%|██████████| 105/105 [00:21<00:00,  4.93it/s, lossD=2, lossG=0.581]    \n",
      "cGAN epoch 51/100: 100%|██████████| 105/105 [00:22<00:00,  4.64it/s, lossD=2.08, lossG=1.55]  \n",
      "cGAN epoch 52/100: 100%|██████████| 105/105 [00:21<00:00,  4.90it/s, lossD=2.27, lossG=0.993] \n",
      "cGAN epoch 53/100: 100%|██████████| 105/105 [00:20<00:00,  5.08it/s, lossD=2.1, lossG=0.864]  \n",
      "cGAN epoch 54/100: 100%|██████████| 105/105 [00:21<00:00,  4.83it/s, lossD=2.01, lossG=0.815]\n",
      "cGAN epoch 55/100: 100%|██████████| 105/105 [00:22<00:00,  4.75it/s, lossD=2.92, lossG=1.56]  \n",
      "cGAN epoch 56/100: 100%|██████████| 105/105 [00:20<00:00,  5.01it/s, lossD=2.02, lossG=0.743] \n",
      "cGAN epoch 57/100: 100%|██████████| 105/105 [00:22<00:00,  4.70it/s, lossD=2.37, lossG=0.354] \n",
      "cGAN epoch 58/100: 100%|██████████| 105/105 [00:21<00:00,  4.78it/s, lossD=2.16, lossG=1.04]  \n",
      "cGAN epoch 59/100: 100%|██████████| 105/105 [00:21<00:00,  4.97it/s, lossD=2.11, lossG=0.385] \n",
      "cGAN epoch 60/100: 100%|██████████| 105/105 [00:22<00:00,  4.66it/s, lossD=2.2, lossG=0.42]  \n",
      "cGAN epoch 61/100: 100%|██████████| 105/105 [00:21<00:00,  4.78it/s, lossD=2.1, lossG=0.7]   \n",
      "cGAN epoch 62/100: 100%|██████████| 105/105 [00:21<00:00,  4.96it/s, lossD=2.05, lossG=1.47]  \n",
      "cGAN epoch 63/100: 100%|██████████| 105/105 [00:19<00:00,  5.38it/s, lossD=1.97, lossG=0.797] \n",
      "cGAN epoch 64/100: 100%|██████████| 105/105 [00:19<00:00,  5.49it/s, lossD=2.09, lossG=0.632] \n",
      "cGAN epoch 65/100: 100%|██████████| 105/105 [00:27<00:00,  3.80it/s, lossD=2.18, lossG=0.389] \n",
      "cGAN epoch 66/100: 100%|██████████| 105/105 [00:20<00:00,  5.23it/s, lossD=2.24, lossG=0.807] \n",
      "cGAN epoch 67/100: 100%|██████████| 105/105 [00:23<00:00,  4.49it/s, lossD=2.04, lossG=1.18]   \n",
      "cGAN epoch 68/100: 100%|██████████| 105/105 [00:19<00:00,  5.31it/s, lossD=2.06, lossG=1.38]  \n",
      "cGAN epoch 69/100: 100%|██████████| 105/105 [00:19<00:00,  5.32it/s, lossD=2.15, lossG=0.123] \n",
      "cGAN epoch 70/100: 100%|██████████| 105/105 [00:19<00:00,  5.44it/s, lossD=2.01, lossG=-0.438]\n",
      "cGAN epoch 71/100: 100%|██████████| 105/105 [00:19<00:00,  5.51it/s, lossD=2.41, lossG=1.49]  \n",
      "cGAN epoch 72/100: 100%|██████████| 105/105 [00:22<00:00,  4.74it/s, lossD=2.06, lossG=0.993]  \n",
      "cGAN epoch 73/100: 100%|██████████| 105/105 [00:19<00:00,  5.30it/s, lossD=1.87, lossG=0.903] \n",
      "cGAN epoch 74/100: 100%|██████████| 105/105 [00:19<00:00,  5.47it/s, lossD=1.7, lossG=0.894]  \n",
      "cGAN epoch 75/100: 100%|██████████| 105/105 [00:19<00:00,  5.40it/s, lossD=2.01, lossG=0.31]  \n",
      "cGAN epoch 76/100: 100%|██████████| 105/105 [00:26<00:00,  3.97it/s, lossD=2.14, lossG=1.11]  \n",
      "cGAN epoch 77/100: 100%|██████████| 105/105 [00:27<00:00,  3.86it/s, lossD=1.88, lossG=1.1]   \n",
      "cGAN epoch 78/100: 100%|██████████| 105/105 [00:27<00:00,  3.86it/s, lossD=2.14, lossG=0.995] \n",
      "cGAN epoch 79/100: 100%|██████████| 105/105 [00:34<00:00,  3.07it/s, lossD=2.25, lossG=1.06]  \n",
      "cGAN epoch 80/100: 100%|██████████| 105/105 [00:33<00:00,  3.10it/s, lossD=1.93, lossG=-0.21]  \n",
      "cGAN epoch 81/100: 100%|██████████| 105/105 [00:31<00:00,  3.31it/s, lossD=1.87, lossG=0.118] \n",
      "cGAN epoch 82/100: 100%|██████████| 105/105 [00:23<00:00,  4.44it/s, lossD=1.97, lossG=-0.726]\n",
      "cGAN epoch 83/100: 100%|██████████| 105/105 [00:20<00:00,  5.18it/s, lossD=2.07, lossG=0.432] \n",
      "cGAN epoch 84/100: 100%|██████████| 105/105 [00:33<00:00,  3.12it/s, lossD=2.59, lossG=0.491] \n",
      "cGAN epoch 85/100: 100%|██████████| 105/105 [00:26<00:00,  3.98it/s, lossD=2.15, lossG=0.447] \n",
      "cGAN epoch 86/100: 100%|██████████| 105/105 [00:27<00:00,  3.78it/s, lossD=2.07, lossG=1.02]  \n",
      "cGAN epoch 87/100: 100%|██████████| 105/105 [00:24<00:00,  4.34it/s, lossD=2.24, lossG=0.649]  \n",
      "cGAN epoch 88/100: 100%|██████████| 105/105 [00:28<00:00,  3.72it/s, lossD=1.89, lossG=0.902] \n",
      "cGAN epoch 89/100: 100%|██████████| 105/105 [00:32<00:00,  3.20it/s, lossD=2.19, lossG=0.623]  \n",
      "cGAN epoch 90/100: 100%|██████████| 105/105 [00:32<00:00,  3.24it/s, lossD=1.94, lossG=1.18]  \n",
      "cGAN epoch 91/100: 100%|██████████| 105/105 [00:27<00:00,  3.84it/s, lossD=1.94, lossG=0.721] \n",
      "cGAN epoch 92/100: 100%|██████████| 105/105 [00:22<00:00,  4.66it/s, lossD=2.15, lossG=0.734] \n",
      "cGAN epoch 93/100: 100%|██████████| 105/105 [00:19<00:00,  5.50it/s, lossD=1.99, lossG=0.575] \n",
      "cGAN epoch 94/100: 100%|██████████| 105/105 [00:18<00:00,  5.55it/s, lossD=2, lossG=0.979]    \n",
      "cGAN epoch 95/100: 100%|██████████| 105/105 [00:18<00:00,  5.54it/s, lossD=2.17, lossG=0.274]\n",
      "cGAN epoch 96/100: 100%|██████████| 105/105 [00:18<00:00,  5.53it/s, lossD=2.13, lossG=1.04]   \n",
      "cGAN epoch 97/100: 100%|██████████| 105/105 [00:18<00:00,  5.60it/s, lossD=2.04, lossG=1.23]  \n",
      "cGAN epoch 98/100: 100%|██████████| 105/105 [00:18<00:00,  5.53it/s, lossD=1.85, lossG=1.34]  \n",
      "cGAN epoch 99/100: 100%|██████████| 105/105 [00:18<00:00,  5.55it/s, lossD=2.32, lossG=-0.361]\n",
      "cGAN epoch 100/100: 100%|██████████| 105/105 [00:18<00:00,  5.53it/s, lossD=2.08, lossG=1.63]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_cgan(loader, epochs=NUM_EPOCHS_GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "601a6396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2209, -0.2939, -0.3764,  ..., -0.7371, -0.6452, -0.5424],\n",
       "          [-0.3769, -0.3045, -0.3626,  ..., -0.7341, -0.6815, -0.5002],\n",
       "          [-0.3659, -0.1786, -0.1979,  ..., -0.4930, -0.4037, -0.4779],\n",
       "          ...,\n",
       "          [ 0.0769,  0.4897,  0.5567,  ..., -0.6894, -0.7427, -0.6826],\n",
       "          [-0.0132,  0.3099,  0.3503,  ..., -0.6484, -0.6385, -0.7146],\n",
       "          [-0.0366, -0.0117,  0.0284,  ..., -0.7902, -0.6847, -0.5509]],\n",
       "\n",
       "         [[-0.2958, -0.3286, -0.4163,  ..., -0.7170, -0.6352, -0.5236],\n",
       "          [-0.4892, -0.3471, -0.3526,  ..., -0.7495, -0.6043, -0.5995],\n",
       "          [-0.3857, -0.2064, -0.3254,  ..., -0.5928, -0.5159, -0.5104],\n",
       "          ...,\n",
       "          [-0.0296,  0.3346,  0.5569,  ..., -0.7462, -0.7754, -0.7273],\n",
       "          [-0.0726,  0.2254,  0.4042,  ..., -0.7169, -0.7216, -0.7402],\n",
       "          [-0.0597, -0.1403, -0.0203,  ..., -0.8036, -0.6572, -0.5635]],\n",
       "\n",
       "         [[-0.3007, -0.5153, -0.4602,  ..., -0.8684, -0.8022, -0.6077],\n",
       "          [-0.4827, -0.5479, -0.5130,  ..., -0.8392, -0.8030, -0.7025],\n",
       "          [-0.5038, -0.5066, -0.4447,  ..., -0.7703, -0.6924, -0.7112],\n",
       "          ...,\n",
       "          [-0.0907,  0.1764,  0.4138,  ..., -0.8169, -0.7562, -0.8267],\n",
       "          [-0.2760, -0.1072,  0.2239,  ..., -0.7900, -0.6055, -0.7791],\n",
       "          [-0.1847, -0.3120, -0.1937,  ..., -0.7967, -0.7912, -0.6280]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_cgan(\"dog\", n = 1, save_path=OUT_DIR / \"generation_dog.png\")\n",
    "generate_cgan(\"lion\", n = 1, save_path=OUT_DIR / \"generation_lion.png\")\n",
    "generate_cgan(\"cat\", n = 1, save_path=OUT_DIR / \"generation_cat.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
