{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3a67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "IMAGE_SIZE = 64\n",
    "BATCH = 128\n",
    "LATENT_DIM = 256\n",
    "NUM_EPOCHS = 80\n",
    "LR = 2e-4\n",
    "EMBED_DIM = 128   \n",
    "BASE_CHANNELS = 64\n",
    "BETA = 1.0     \n",
    "SAMPLE_PER_CLASS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"data/animals\")\n",
    "OUT_DIR = Path(\"outputs_cvae\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd1531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13474 images, 5 classes: ['cat', 'dog', 'elephant', 'horse', 'lion']\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  \n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=str(DATA_ROOT), transform=tf)\n",
    "if len(dataset) == 0:\n",
    "    raise RuntimeError(f\"No images found in {DATA_ROOT}\")\n",
    "\n",
    "class_names = dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Found {len(dataset)} images, {NUM_CLASSES} classes:\", class_names)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=(DEVICE.type==\"cuda\"), drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Утилиты\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def save_image_grid(tensor, path, nrow=8):\n",
    "    tensor = tensor.clamp(-1, 1)\n",
    "    save_image((tensor + 1) / 2, path, nrow=nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE model (Encoder + Decoder + reparam)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_channels=3, base=BASE_CHANNELS, embed_dim=EMBED_DIM, n_classes=NUM_CLASSES, latent_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, base, 4, 2, 1), nn.BatchNorm2d(base), nn.ReLU(True),\n",
    "            nn.Conv2d(base, base*2, 4, 2, 1), nn.BatchNorm2d(base*2), nn.ReLU(True),\n",
    "            nn.Conv2d(base*2, base*4, 4, 2, 1), nn.BatchNorm2d(base*4), nn.ReLU(True),\n",
    "            nn.Conv2d(base*4, base*8, 4, 2, 1), nn.BatchNorm2d(base*8), nn.ReLU(True)\n",
    "        )\n",
    "        feat_dim = base*8*4*4\n",
    "        self.label_emb = nn.Embedding(n_classes, embed_dim)\n",
    "\n",
    "        self.fc_mu = nn.Linear(feat_dim + embed_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(feat_dim + embed_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        b = x.size(0)\n",
    "        f = self.conv(x)         \n",
    "        f = f.view(b, -1)        \n",
    "        le = self.label_emb(labels)  \n",
    "        h = torch.cat([f, le], dim=1)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_channels=3, base=BASE_CHANNELS, embed_dim=EMBED_DIM, n_classes=NUM_CLASSES, latent_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, embed_dim)\n",
    "        self.latent_input_dim = latent_dim + embed_dim\n",
    "        self.fc = nn.Linear(self.latent_input_dim, base*8*4*4)\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base*8, base*4, 4, 2, 1), nn.BatchNorm2d(base*4), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(base*4, base*2, 4, 2, 1), nn.BatchNorm2d(base*2), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(base*2, base, 4, 2, 1), nn.BatchNorm2d(base), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(base, img_channels, 4, 2, 1),\n",
    "            nn.Tanh()   # outputs in [-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        le = self.label_emb(labels)\n",
    "        z_cond = torch.cat([z, le], dim=1)  \n",
    "        x = self.fc(z_cond)\n",
    "        x = x.view(-1, BASE_CHANNELS*8, 4, 4)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, n_classes=NUM_CLASSES, latent_dim=LATENT_DIM, embed_dim=EMBED_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(n_classes=n_classes, latent_dim=latent_dim, embed_dim=embed_dim)\n",
    "        self.decoder = Decoder(n_classes=n_classes, latent_dim=latent_dim, embed_dim=embed_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = (0.5 * logvar).exp()   # exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        mu, logvar = self.encoder(x, labels)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z, labels)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "model = ConditionalVAE(n_classes=NUM_CLASSES, latent_dim=LATENT_DIM, embed_dim=EMBED_DIM).to(DEVICE)\n",
    "model.apply(weights_init)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# fixed noise/labels для визуализации \n",
    "fixed_z = torch.randn(NUM_CLASSES * SAMPLE_PER_CLASS, LATENT_DIM, device=DEVICE)\n",
    "fixed_labels = torch.tensor([i for i in range(NUM_CLASSES) for _ in range(SAMPLE_PER_CLASS)], device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c39c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss функции и train step\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    # KL divergence\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss, kld\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device, epoch, beta=BETA):\n",
    "    model.train()\n",
    "    running_recon = 0.0\n",
    "    running_kld = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"CVAE epoch {epoch+1}\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(imgs, labels)\n",
    "        recon_loss, kld = loss_function(recon, imgs, mu, logvar)\n",
    "        loss = recon_loss + beta * kld\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_recon += float(recon_loss.item())\n",
    "        running_kld += float(kld.item())\n",
    "        pbar.set_postfix({'recon': running_recon/ (pbar.n+1), 'kld': running_kld/(pbar.n+1)})\n",
    "    return running_recon/len(loader), running_kld/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции сохранения примеров / генерации / реконструкции\n",
    "def save_reconstructions(model, data_loader, path, n=8):\n",
    "    model.eval()\n",
    "    imgs, labels = next(iter(data_loader))\n",
    "    imgs = imgs[:n].to(DEVICE)\n",
    "    labels = labels[:n].to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        recon, _, _ = model(imgs, labels)\n",
    "    cat = torch.cat([imgs.cpu(), recon.cpu()], dim=0)\n",
    "    save_image_grid(cat, path, nrow=n)\n",
    "\n",
    "def generate_by_class(model, class_idx, n=8, save_path=None):\n",
    "    model.eval()\n",
    "    z = torch.randn(n, LATENT_DIM, device=DEVICE)\n",
    "    labels = torch.tensor([class_idx]*n, device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        imgs = model.decoder(z, labels).cpu()\n",
    "    if save_path:\n",
    "        save_image_grid(imgs, save_path, nrow=n)\n",
    "    return imgs\n",
    "\n",
    "def sample_grid_fixed(model, fixed_z, fixed_labels, save_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = fixed_z.to(DEVICE)\n",
    "        labels = fixed_labels.to(DEVICE)\n",
    "        imgs = model.decoder(z, labels).cpu()\n",
    "    save_image_grid(imgs, save_path, nrow=SAMPLE_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3619b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 1: 100%|██████████| 105/105 [00:21<00:00,  4.84it/s, recon=0.196, kld=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: recon=0.19074, kld=0.14655, saved: recon_epoch1.png, samples_epoch1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 2: 100%|██████████| 105/105 [00:42<00:00,  2.49it/s, recon=0.159, kld=0.0445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: recon=0.15771, kld=0.04403, saved: recon_epoch2.png, samples_epoch2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 3: 100%|██████████| 105/105 [00:37<00:00,  2.79it/s, recon=0.152, kld=0.0396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: recon=0.15214, kld=0.03964, saved: recon_epoch3.png, samples_epoch3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 4: 100%|██████████| 105/105 [00:43<00:00,  2.40it/s, recon=0.147, kld=0.0374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: recon=0.14722, kld=0.03740, saved: recon_epoch4.png, samples_epoch4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 5: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s, recon=0.144, kld=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: recon=0.14114, kld=0.03515, saved: recon_epoch5.png, samples_epoch5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 6: 100%|██████████| 105/105 [00:38<00:00,  2.75it/s, recon=0.138, kld=0.0335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: recon=0.13668, kld=0.03321, saved: recon_epoch6.png, samples_epoch6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 7: 100%|██████████| 105/105 [00:21<00:00,  4.92it/s, recon=0.133, kld=0.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: recon=0.13345, kld=0.03218, saved: recon_epoch7.png, samples_epoch7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 8: 100%|██████████| 105/105 [00:22<00:00,  4.75it/s, recon=0.132, kld=0.032] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: recon=0.13094, kld=0.03165, saved: recon_epoch8.png, samples_epoch8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 9: 100%|██████████| 105/105 [00:21<00:00,  4.87it/s, recon=0.13, kld=0.0318] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: recon=0.12901, kld=0.03150, saved: recon_epoch9.png, samples_epoch9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 10: 100%|██████████| 105/105 [00:34<00:00,  3.01it/s, recon=0.132, kld=0.0325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: recon=0.12800, kld=0.03158, saved: recon_epoch10.png, samples_epoch10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 11: 100%|██████████| 105/105 [00:27<00:00,  3.86it/s, recon=0.127, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: recon=0.12697, kld=0.03142, saved: recon_epoch11.png, samples_epoch11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 12: 100%|██████████| 105/105 [00:32<00:00,  3.21it/s, recon=0.126, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: recon=0.12615, kld=0.03134, saved: recon_epoch12.png, samples_epoch12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 13: 100%|██████████| 105/105 [00:45<00:00,  2.31it/s, recon=0.127, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: recon=0.12578, kld=0.03107, saved: recon_epoch13.png, samples_epoch13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 14: 100%|██████████| 105/105 [00:42<00:00,  2.47it/s, recon=0.127, kld=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: recon=0.12548, kld=0.03116, saved: recon_epoch14.png, samples_epoch14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 15: 100%|██████████| 105/105 [00:25<00:00,  4.06it/s, recon=0.126, kld=0.0318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: recon=0.12498, kld=0.03149, saved: recon_epoch15.png, samples_epoch15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 16: 100%|██████████| 105/105 [00:25<00:00,  4.08it/s, recon=0.128, kld=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: recon=0.12476, kld=0.03064, saved: recon_epoch16.png, samples_epoch16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 17: 100%|██████████| 105/105 [00:22<00:00,  4.62it/s, recon=0.125, kld=0.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: recon=0.12457, kld=0.03108, saved: recon_epoch17.png, samples_epoch17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 18: 100%|██████████| 105/105 [00:22<00:00,  4.58it/s, recon=0.125, kld=0.031] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: recon=0.12430, kld=0.03071, saved: recon_epoch18.png, samples_epoch18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 19: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s, recon=0.126, kld=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: recon=0.12369, kld=0.03058, saved: recon_epoch19.png, samples_epoch19.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 20: 100%|██████████| 105/105 [00:28<00:00,  3.66it/s, recon=0.125, kld=0.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: recon=0.12349, kld=0.03078, saved: recon_epoch20.png, samples_epoch20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 21: 100%|██████████| 105/105 [00:29<00:00,  3.53it/s, recon=0.123, kld=0.0303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: recon=0.12322, kld=0.03030, saved: recon_epoch21.png, samples_epoch21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 22: 100%|██████████| 105/105 [00:26<00:00,  3.99it/s, recon=0.125, kld=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: recon=0.12300, kld=0.03065, saved: recon_epoch22.png, samples_epoch22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 23: 100%|██████████| 105/105 [00:23<00:00,  4.40it/s, recon=0.125, kld=0.0309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: recon=0.12283, kld=0.03032, saved: recon_epoch23.png, samples_epoch23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 24: 100%|██████████| 105/105 [00:22<00:00,  4.77it/s, recon=0.123, kld=0.0309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: recon=0.12220, kld=0.03056, saved: recon_epoch24.png, samples_epoch24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 25: 100%|██████████| 105/105 [00:21<00:00,  4.89it/s, recon=0.122, kld=0.0309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: recon=0.12171, kld=0.03095, saved: recon_epoch25.png, samples_epoch25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 26: 100%|██████████| 105/105 [00:26<00:00,  3.91it/s, recon=0.125, kld=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: recon=0.12106, kld=0.03175, saved: recon_epoch26.png, samples_epoch26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 27: 100%|██████████| 105/105 [00:27<00:00,  3.82it/s, recon=0.123, kld=0.0318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: recon=0.12040, kld=0.03124, saved: recon_epoch27.png, samples_epoch27.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 28: 100%|██████████| 105/105 [00:26<00:00,  4.00it/s, recon=0.122, kld=0.0329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: recon=0.12045, kld=0.03259, saved: recon_epoch28.png, samples_epoch28.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 29: 100%|██████████| 105/105 [00:23<00:00,  4.42it/s, recon=0.121, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: recon=0.11987, kld=0.03114, saved: recon_epoch29.png, samples_epoch29.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 30: 100%|██████████| 105/105 [00:23<00:00,  4.39it/s, recon=0.123, kld=0.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: recon=0.11944, kld=0.03124, saved: recon_epoch30.png, samples_epoch30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 31: 100%|██████████| 105/105 [00:25<00:00,  4.16it/s, recon=0.123, kld=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: recon=0.11939, kld=0.03080, saved: recon_epoch31.png, samples_epoch31.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 32: 100%|██████████| 105/105 [00:21<00:00,  4.93it/s, recon=0.122, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: recon=0.11937, kld=0.03129, saved: recon_epoch32.png, samples_epoch32.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 33: 100%|██████████| 105/105 [00:22<00:00,  4.77it/s, recon=0.123, kld=0.0431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: recon=0.12154, kld=0.04269, saved: recon_epoch33.png, samples_epoch33.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 34: 100%|██████████| 105/105 [00:25<00:00,  4.07it/s, recon=0.119, kld=0.0306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: recon=0.11908, kld=0.03058, saved: recon_epoch34.png, samples_epoch34.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 35: 100%|██████████| 105/105 [00:25<00:00,  4.15it/s, recon=0.121, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: recon=0.11887, kld=0.03074, saved: recon_epoch35.png, samples_epoch35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 36: 100%|██████████| 105/105 [00:20<00:00,  5.11it/s, recon=0.12, kld=0.031]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: recon=0.11877, kld=0.03070, saved: recon_epoch36.png, samples_epoch36.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 37: 100%|██████████| 105/105 [00:17<00:00,  6.00it/s, recon=0.12, kld=0.0311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: recon=0.11857, kld=0.03078, saved: recon_epoch37.png, samples_epoch37.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 38: 100%|██████████| 105/105 [00:20<00:00,  5.15it/s, recon=0.118, kld=0.0308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: recon=0.11812, kld=0.03080, saved: recon_epoch38.png, samples_epoch38.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 39: 100%|██████████| 105/105 [00:17<00:00,  6.05it/s, recon=0.119, kld=0.0309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: recon=0.11862, kld=0.03087, saved: recon_epoch39.png, samples_epoch39.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 40: 100%|██████████| 105/105 [00:18<00:00,  5.59it/s, recon=0.119, kld=0.031] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: recon=0.11795, kld=0.03072, saved: recon_epoch40.png, samples_epoch40.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 41: 100%|██████████| 105/105 [00:21<00:00,  4.97it/s, recon=0.12, kld=0.0316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: recon=0.11809, kld=0.03098, saved: recon_epoch41.png, samples_epoch41.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 42: 100%|██████████| 105/105 [00:22<00:00,  4.67it/s, recon=0.121, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: recon=0.11770, kld=0.03099, saved: recon_epoch42.png, samples_epoch42.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 43: 100%|██████████| 105/105 [00:21<00:00,  4.93it/s, recon=0.118, kld=0.031] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: recon=0.11778, kld=0.03098, saved: recon_epoch43.png, samples_epoch43.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 44: 100%|██████████| 105/105 [00:21<00:00,  4.78it/s, recon=0.118, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: recon=0.11718, kld=0.03110, saved: recon_epoch44.png, samples_epoch44.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 45: 100%|██████████| 105/105 [00:48<00:00,  2.18it/s, recon=0.12, kld=0.0317] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: recon=0.11733, kld=0.03107, saved: recon_epoch45.png, samples_epoch45.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 46: 100%|██████████| 105/105 [00:29<00:00,  3.55it/s, recon=0.121, kld=0.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: recon=0.11737, kld=0.03128, saved: recon_epoch46.png, samples_epoch46.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 47: 100%|██████████| 105/105 [00:39<00:00,  2.68it/s, recon=0.119, kld=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: recon=0.11677, kld=0.03110, saved: recon_epoch47.png, samples_epoch47.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 48: 100%|██████████| 105/105 [00:48<00:00,  2.17it/s, recon=0.119, kld=0.032] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: recon=0.11682, kld=0.03139, saved: recon_epoch48.png, samples_epoch48.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 49: 100%|██████████| 105/105 [00:37<00:00,  2.83it/s, recon=0.117, kld=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: recon=0.11636, kld=0.03124, saved: recon_epoch49.png, samples_epoch49.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 50: 100%|██████████| 105/105 [00:32<00:00,  3.20it/s, recon=0.118, kld=0.0318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: recon=0.11623, kld=0.03120, saved: recon_epoch50.png, samples_epoch50.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 51: 100%|██████████| 105/105 [00:50<00:00,  2.10it/s, recon=0.118, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: recon=0.11606, kld=0.03130, saved: recon_epoch51.png, samples_epoch51.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 52: 100%|██████████| 105/105 [00:49<00:00,  2.11it/s, recon=0.116, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: recon=0.11592, kld=0.03138, saved: recon_epoch52.png, samples_epoch52.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 53: 100%|██████████| 105/105 [00:40<00:00,  2.61it/s, recon=0.12, kld=0.0321] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: recon=0.11624, kld=0.03120, saved: recon_epoch53.png, samples_epoch53.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 54: 100%|██████████| 105/105 [00:46<00:00,  2.26it/s, recon=0.12, kld=0.0649] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: recon=0.11950, kld=0.06488, saved: recon_epoch54.png, samples_epoch54.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 55: 100%|██████████| 105/105 [00:41<00:00,  2.54it/s, recon=0.118, kld=0.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: recon=0.11786, kld=0.03109, saved: recon_epoch55.png, samples_epoch55.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 56: 100%|██████████| 105/105 [00:44<00:00,  2.35it/s, recon=0.117, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: recon=0.11632, kld=0.03110, saved: recon_epoch56.png, samples_epoch56.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 57: 100%|██████████| 105/105 [00:20<00:00,  5.15it/s, recon=0.118, kld=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: recon=0.11604, kld=0.03107, saved: recon_epoch57.png, samples_epoch57.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 58: 100%|██████████| 105/105 [00:19<00:00,  5.25it/s, recon=0.117, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: recon=0.11603, kld=0.03101, saved: recon_epoch58.png, samples_epoch58.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 59: 100%|██████████| 105/105 [00:20<00:00,  5.08it/s, recon=0.118, kld=0.0316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: recon=0.11582, kld=0.03102, saved: recon_epoch59.png, samples_epoch59.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 60: 100%|██████████| 105/105 [00:20<00:00,  5.20it/s, recon=0.119, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: recon=0.11568, kld=0.03100, saved: recon_epoch60.png, samples_epoch60.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 61: 100%|██████████| 105/105 [00:32<00:00,  3.18it/s, recon=0.115, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: recon=0.11541, kld=0.03135, saved: recon_epoch61.png, samples_epoch61.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 62: 100%|██████████| 105/105 [00:19<00:00,  5.29it/s, recon=0.117, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: recon=0.11540, kld=0.03106, saved: recon_epoch62.png, samples_epoch62.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 63: 100%|██████████| 105/105 [00:20<00:00,  5.17it/s, recon=0.117, kld=0.0314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: recon=0.11540, kld=0.03110, saved: recon_epoch63.png, samples_epoch63.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 64: 100%|██████████| 105/105 [00:19<00:00,  5.26it/s, recon=0.116, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: recon=0.11524, kld=0.03101, saved: recon_epoch64.png, samples_epoch64.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 65: 100%|██████████| 105/105 [00:20<00:00,  5.08it/s, recon=0.119, kld=0.0321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: recon=0.11527, kld=0.03120, saved: recon_epoch65.png, samples_epoch65.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 66: 100%|██████████| 105/105 [00:21<00:00,  4.78it/s, recon=0.115, kld=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: recon=0.11497, kld=0.03119, saved: recon_epoch66.png, samples_epoch66.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 67: 100%|██████████| 105/105 [00:29<00:00,  3.54it/s, recon=0.115, kld=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: recon=0.11491, kld=0.03122, saved: recon_epoch67.png, samples_epoch67.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 68: 100%|██████████| 105/105 [00:41<00:00,  2.53it/s, recon=0.115, kld=0.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: recon=0.11497, kld=0.03112, saved: recon_epoch68.png, samples_epoch68.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 69: 100%|██████████| 105/105 [00:19<00:00,  5.31it/s, recon=0.115, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: recon=0.11491, kld=0.03130, saved: recon_epoch69.png, samples_epoch69.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 70: 100%|██████████| 105/105 [00:20<00:00,  5.21it/s, recon=0.118, kld=0.032] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: recon=0.11462, kld=0.03110, saved: recon_epoch70.png, samples_epoch70.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 71: 100%|██████████| 105/105 [00:19<00:00,  5.29it/s, recon=0.117, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: recon=0.11453, kld=0.03129, saved: recon_epoch71.png, samples_epoch71.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 72: 100%|██████████| 105/105 [00:20<00:00,  5.21it/s, recon=0.117, kld=0.0319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: recon=0.11444, kld=0.03134, saved: recon_epoch72.png, samples_epoch72.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 73: 100%|██████████| 105/105 [00:19<00:00,  5.34it/s, recon=0.116, kld=0.0315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: recon=0.11442, kld=0.03119, saved: recon_epoch73.png, samples_epoch73.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 74: 100%|██████████| 105/105 [00:20<00:00,  5.19it/s, recon=0.115, kld=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: recon=0.11455, kld=0.03122, saved: recon_epoch74.png, samples_epoch74.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 75: 100%|██████████| 105/105 [00:19<00:00,  5.31it/s, recon=0.114, kld=0.0313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: recon=0.11430, kld=0.03131, saved: recon_epoch75.png, samples_epoch75.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 76: 100%|██████████| 105/105 [00:21<00:00,  4.91it/s, recon=0.115, kld=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: recon=0.11412, kld=0.03139, saved: recon_epoch76.png, samples_epoch76.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 77: 100%|██████████| 105/105 [00:21<00:00,  4.83it/s, recon=0.116, kld=0.0321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: recon=0.11403, kld=0.03145, saved: recon_epoch77.png, samples_epoch77.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 78: 100%|██████████| 105/105 [00:21<00:00,  4.91it/s, recon=0.115, kld=0.0318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: recon=0.11369, kld=0.03151, saved: recon_epoch78.png, samples_epoch78.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 79: 100%|██████████| 105/105 [00:21<00:00,  4.97it/s, recon=0.115, kld=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: recon=0.11398, kld=0.03138, saved: recon_epoch79.png, samples_epoch79.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE epoch 80: 100%|██████████| 105/105 [00:21<00:00,  4.90it/s, recon=0.117, kld=0.0325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: recon=0.11358, kld=0.03153, saved: recon_epoch80.png, samples_epoch80.png\n",
      "Training finished. Models and examples saved to outputs_cvae\n"
     ]
    }
   ],
   "source": [
    "# training loop, чекпоинты, примеры\n",
    "best_loss = 1e9\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    recon_avg, kld_avg = train_epoch(model, loader, optimizer, DEVICE, epoch, beta=BETA)\n",
    "    recon_path = OUT_DIR / f\"recon_epoch{epoch+1}.png\"\n",
    "    save_reconstructions(model, loader, recon_path, n=8)\n",
    "\n",
    "    samples_path = OUT_DIR / f\"samples_epoch{epoch+1}.png\"\n",
    "    sample_grid_fixed(model, fixed_z, fixed_labels, samples_path)\n",
    "\n",
    "    # чекпоинты\n",
    "    torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state': model.state_dict(),\n",
    "        'opt_state': optimizer.state_dict()\n",
    "    }, OUT_DIR / f\"cvae_checkpoint_epoch{epoch+1}.pth\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: recon={recon_avg:.5f}, kld={kld_avg:.5f}, saved: {recon_path.name}, {samples_path.name}\")\n",
    "\n",
    "# финальное сохранение\n",
    "torch.save(model.state_dict(), OUT_DIR / \"cvae_final.pth\")\n",
    "print(\"Training finished. Models and examples saved to\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3132e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generation grid for first 5 classes: outputs_cvae\\generation_first5_classes.png\n"
     ]
    }
   ],
   "source": [
    "# пример использования генерации и визуализации нескольких классов\n",
    "\n",
    "grid_imgs = []\n",
    "grid_labels = []\n",
    "n_per = SAMPLE_PER_CLASS\n",
    "for cls_idx in range(min(5, NUM_CLASSES)):\n",
    "    imgs = generate_by_class(model, cls_idx, n=n_per)\n",
    "    grid_imgs.append(imgs)\n",
    "    grid_labels += [class_names[cls_idx]] * n_per\n",
    "\n",
    "# Склеим все в один тензор и сохраним\n",
    "grid = torch.cat(grid_imgs, dim=0)\n",
    "save_image_grid(grid, OUT_DIR / \"generation_first5_classes.png\", nrow=n_per)\n",
    "print(\"Saved generation grid for first 5 classes:\", OUT_DIR / \"generation_first5_classes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c2ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_name_to_index(name):\n",
    "    lowered = [c.lower() for c in class_names]\n",
    "    name_l = name.lower()\n",
    "    if name_l in lowered:\n",
    "        return lowered.index(name_l)\n",
    "    for i,c in enumerate(lowered):\n",
    "        if c.startswith(name_l) or name_l in c:\n",
    "            return i\n",
    "    raise ValueError(\"class not found\")\n",
    "\n",
    "def generate_by_name(name, n=6, save_path=None):\n",
    "    idx = class_name_to_index(name)\n",
    "    imgs = generate_by_class(model, idx, n=n, save_path=save_path)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c926ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0124, -0.0080, -0.0059,  ..., -0.0971, -0.1025, -0.0863],\n",
       "          [ 0.0140,  0.0281,  0.0162,  ..., -0.1067, -0.1138, -0.0859],\n",
       "          [ 0.0371,  0.0512,  0.0413,  ..., -0.1023, -0.1044, -0.0994],\n",
       "          ...,\n",
       "          [-0.7692, -0.8026, -0.7991,  ..., -0.2506, -0.2410, -0.2230],\n",
       "          [-0.7388, -0.7971, -0.7912,  ..., -0.2435, -0.2424, -0.2243],\n",
       "          [-0.6510, -0.7470, -0.7439,  ..., -0.2277, -0.2386, -0.1950]],\n",
       "\n",
       "         [[ 0.0254,  0.0524,  0.0460,  ..., -0.0526, -0.0622, -0.0706],\n",
       "          [ 0.0718,  0.0880,  0.0693,  ..., -0.0501, -0.0564, -0.0588],\n",
       "          [ 0.0763,  0.1024,  0.1119,  ..., -0.0303, -0.0436, -0.0678],\n",
       "          ...,\n",
       "          [-0.7571, -0.8004, -0.7883,  ..., -0.2419, -0.2411, -0.2256],\n",
       "          [-0.7566, -0.7982, -0.8025,  ..., -0.2423, -0.2364, -0.2307],\n",
       "          [-0.6594, -0.7596, -0.7627,  ..., -0.2615, -0.2501, -0.2247]],\n",
       "\n",
       "         [[-0.0440, -0.0457, -0.0523,  ..., -0.1836, -0.1927, -0.1924],\n",
       "          [-0.0232, -0.0304, -0.0282,  ..., -0.1828, -0.2024, -0.1885],\n",
       "          [-0.0020,  0.0200,  0.0147,  ..., -0.1734, -0.1918, -0.1962],\n",
       "          ...,\n",
       "          [-0.8043, -0.8123, -0.8137,  ..., -0.3358, -0.3370, -0.3568],\n",
       "          [-0.8039, -0.8325, -0.8182,  ..., -0.3518, -0.3468, -0.3599],\n",
       "          [-0.7467, -0.7987, -0.8096,  ..., -0.3574, -0.3737, -0.3648]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2506,  0.2783,  0.2703,  ...,  0.3929,  0.3962,  0.3410],\n",
       "          [ 0.2855,  0.2578,  0.2606,  ...,  0.3845,  0.3746,  0.3771],\n",
       "          [ 0.2584,  0.2575,  0.2538,  ...,  0.3658,  0.3777,  0.3745],\n",
       "          ...,\n",
       "          [ 0.2191,  0.2441,  0.2486,  ...,  0.6087,  0.5990,  0.5713],\n",
       "          [ 0.2413,  0.2621,  0.2811,  ...,  0.5894,  0.5978,  0.5707],\n",
       "          [ 0.2477,  0.2850,  0.3068,  ...,  0.5852,  0.5691,  0.4875]],\n",
       "\n",
       "         [[ 0.2246,  0.2651,  0.2548,  ...,  0.3790,  0.3739,  0.3484],\n",
       "          [ 0.2616,  0.2470,  0.2451,  ...,  0.3696,  0.3708,  0.3655],\n",
       "          [ 0.2374,  0.2389,  0.2370,  ...,  0.3610,  0.3665,  0.3686],\n",
       "          ...,\n",
       "          [ 0.1974,  0.1956,  0.2218,  ...,  0.5840,  0.5794,  0.5738],\n",
       "          [ 0.2236,  0.2201,  0.2406,  ...,  0.5874,  0.5694,  0.5610],\n",
       "          [ 0.1885,  0.2242,  0.2708,  ...,  0.5751,  0.5396,  0.4620]],\n",
       "\n",
       "         [[ 0.1370,  0.1213,  0.1166,  ...,  0.2760,  0.2576,  0.2510],\n",
       "          [ 0.1090,  0.1032,  0.0795,  ...,  0.2347,  0.2393,  0.2444],\n",
       "          [ 0.0964,  0.0881,  0.0772,  ...,  0.2142,  0.2331,  0.2255],\n",
       "          ...,\n",
       "          [ 0.1046,  0.1241,  0.1482,  ...,  0.5592,  0.5331,  0.5240],\n",
       "          [ 0.1197,  0.1418,  0.1743,  ...,  0.5522,  0.5284,  0.4916],\n",
       "          [ 0.0748,  0.1522,  0.1997,  ...,  0.5086,  0.4800,  0.3668]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4514,  0.4962,  0.4922,  ...,  0.5278,  0.5290,  0.4695],\n",
       "          [ 0.5253,  0.5011,  0.4993,  ...,  0.5351,  0.5324,  0.5212],\n",
       "          [ 0.5274,  0.5022,  0.5087,  ...,  0.5208,  0.5407,  0.5318],\n",
       "          ...,\n",
       "          [ 0.2092,  0.2040,  0.1674,  ..., -0.1663, -0.1351, -0.1068],\n",
       "          [ 0.2039,  0.2020,  0.1620,  ..., -0.1754, -0.1481, -0.1161],\n",
       "          [ 0.1532,  0.1804,  0.1613,  ..., -0.1770, -0.1619, -0.1388]],\n",
       "\n",
       "         [[ 0.4317,  0.4961,  0.5066,  ...,  0.5244,  0.5218,  0.4890],\n",
       "          [ 0.5222,  0.5037,  0.5078,  ...,  0.5305,  0.5389,  0.5318],\n",
       "          [ 0.5036,  0.5131,  0.4914,  ...,  0.5257,  0.5347,  0.5408],\n",
       "          ...,\n",
       "          [ 0.1309,  0.1180,  0.0951,  ..., -0.2512, -0.2039, -0.1634],\n",
       "          [ 0.1294,  0.1286,  0.0812,  ..., -0.2410, -0.2225, -0.1857],\n",
       "          [ 0.0707,  0.0787,  0.0734,  ..., -0.2446, -0.2357, -0.1913]],\n",
       "\n",
       "         [[ 0.3936,  0.4320,  0.4389,  ...,  0.4678,  0.4496,  0.4302],\n",
       "          [ 0.4224,  0.4136,  0.3875,  ...,  0.4362,  0.4497,  0.4648],\n",
       "          [ 0.4200,  0.3925,  0.3843,  ...,  0.4208,  0.4450,  0.4454],\n",
       "          ...,\n",
       "          [-0.0564, -0.0900, -0.1265,  ..., -0.3869, -0.3546, -0.3417],\n",
       "          [-0.0719, -0.1002, -0.1244,  ..., -0.4033, -0.3736, -0.3421],\n",
       "          [-0.0987, -0.1246, -0.1267,  ..., -0.3865, -0.3856, -0.3537]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0762,  0.0763,  0.0651,  ...,  0.2351,  0.2372,  0.1967],\n",
       "          [ 0.0897,  0.0574,  0.0474,  ...,  0.2251,  0.2121,  0.2315],\n",
       "          [ 0.0683,  0.0615,  0.0504,  ...,  0.2084,  0.2114,  0.2163],\n",
       "          ...,\n",
       "          [-0.1893, -0.2017, -0.2003,  ..., -0.0265, -0.0210, -0.0242],\n",
       "          [-0.1892, -0.1998, -0.2171,  ..., -0.0279, -0.0264, -0.0190],\n",
       "          [-0.1765, -0.2172, -0.2141,  ..., -0.0236, -0.0298, -0.0282]],\n",
       "\n",
       "         [[ 0.0646,  0.0874,  0.0708,  ...,  0.2251,  0.2245,  0.2057],\n",
       "          [ 0.0838,  0.0853,  0.0715,  ...,  0.2267,  0.2195,  0.2160],\n",
       "          [ 0.0673,  0.0698,  0.0674,  ...,  0.2266,  0.2258,  0.2172],\n",
       "          ...,\n",
       "          [-0.2173, -0.2272, -0.2097,  ..., -0.0774, -0.0575, -0.0610],\n",
       "          [-0.2302, -0.2291, -0.2344,  ..., -0.0623, -0.0639, -0.0640],\n",
       "          [-0.2262, -0.2543, -0.2556,  ..., -0.0795, -0.0784, -0.0852]],\n",
       "\n",
       "         [[-0.0371, -0.0712, -0.0901,  ...,  0.0932,  0.0778,  0.0839],\n",
       "          [-0.0736, -0.0966, -0.1096,  ...,  0.0621,  0.0601,  0.0683],\n",
       "          [-0.0744, -0.0831, -0.1029,  ...,  0.0536,  0.0648,  0.0574],\n",
       "          ...,\n",
       "          [-0.3496, -0.3491, -0.3482,  ..., -0.2359, -0.2310, -0.2465],\n",
       "          [-0.3719, -0.3585, -0.3662,  ..., -0.2514, -0.2426, -0.2405],\n",
       "          [-0.3603, -0.3812, -0.3813,  ..., -0.2297, -0.2434, -0.2485]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0094,  0.0443,  0.0485,  ..., -0.3282, -0.3293, -0.3043],\n",
       "          [ 0.0461,  0.0464,  0.0554,  ..., -0.3397, -0.3349, -0.3302],\n",
       "          [ 0.0404,  0.0561,  0.0658,  ..., -0.3260, -0.3491, -0.3316],\n",
       "          ...,\n",
       "          [-0.1344, -0.1452, -0.1382,  ..., -0.1073, -0.1238, -0.1325],\n",
       "          [-0.1179, -0.1192, -0.1285,  ..., -0.1246, -0.1374, -0.1268],\n",
       "          [-0.0936, -0.1093, -0.1033,  ..., -0.1132, -0.1286, -0.1162]],\n",
       "\n",
       "         [[-0.0137,  0.0143,  0.0133,  ..., -0.3481, -0.3396, -0.3262],\n",
       "          [ 0.0120,  0.0292,  0.0316,  ..., -0.3103, -0.3120, -0.3382],\n",
       "          [ 0.0108,  0.0376,  0.0483,  ..., -0.3114, -0.3193, -0.3497],\n",
       "          ...,\n",
       "          [-0.1742, -0.1820, -0.1673,  ..., -0.1626, -0.1581, -0.1756],\n",
       "          [-0.1673, -0.1706, -0.1641,  ..., -0.1529, -0.1688, -0.1749],\n",
       "          [-0.1541, -0.1612, -0.1555,  ..., -0.1595, -0.1672, -0.1609]],\n",
       "\n",
       "         [[-0.1503, -0.1892, -0.1832,  ..., -0.5211, -0.5112, -0.4752],\n",
       "          [-0.1999, -0.1907, -0.1753,  ..., -0.5078, -0.5000, -0.5118],\n",
       "          [-0.1840, -0.1683, -0.1637,  ..., -0.5019, -0.5212, -0.5211],\n",
       "          ...,\n",
       "          [-0.3220, -0.3208, -0.3158,  ..., -0.3127, -0.3083, -0.3329],\n",
       "          [-0.3255, -0.3062, -0.3008,  ..., -0.3106, -0.3190, -0.3266],\n",
       "          [-0.2975, -0.3015, -0.2925,  ..., -0.2875, -0.3077, -0.3072]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5418,  0.6149,  0.6163,  ...,  0.4066,  0.4134,  0.3305],\n",
       "          [ 0.6482,  0.6531,  0.6553,  ...,  0.3701,  0.3614,  0.3729],\n",
       "          [ 0.6615,  0.6635,  0.6761,  ...,  0.3181,  0.3246,  0.3452],\n",
       "          ...,\n",
       "          [ 0.4453,  0.4741,  0.4822,  ...,  0.4352,  0.4401,  0.4051],\n",
       "          [ 0.4439,  0.4725,  0.4753,  ...,  0.4255,  0.4371,  0.4129],\n",
       "          [ 0.3815,  0.4485,  0.4618,  ...,  0.4349,  0.4204,  0.3536]],\n",
       "\n",
       "         [[ 0.5136,  0.5829,  0.6110,  ...,  0.3377,  0.3384,  0.3133],\n",
       "          [ 0.6289,  0.6175,  0.6337,  ...,  0.2873,  0.2888,  0.2993],\n",
       "          [ 0.6209,  0.6413,  0.6254,  ...,  0.2323,  0.2473,  0.2685],\n",
       "          ...,\n",
       "          [ 0.3822,  0.3884,  0.3931,  ...,  0.3512,  0.3444,  0.3536],\n",
       "          [ 0.3890,  0.4055,  0.3912,  ...,  0.3676,  0.3479,  0.3520],\n",
       "          [ 0.3036,  0.3584,  0.3998,  ...,  0.3770,  0.3460,  0.2916]],\n",
       "\n",
       "         [[ 0.4727,  0.5225,  0.5425,  ...,  0.1851,  0.1776,  0.1917],\n",
       "          [ 0.5166,  0.5224,  0.5023,  ...,  0.0950,  0.1213,  0.1183],\n",
       "          [ 0.5246,  0.5033,  0.4937,  ...,  0.0358,  0.0864,  0.0679],\n",
       "          ...,\n",
       "          [ 0.2232,  0.2060,  0.2199,  ...,  0.1891,  0.1893,  0.2084],\n",
       "          [ 0.2351,  0.2131,  0.2283,  ...,  0.2140,  0.2042,  0.1895],\n",
       "          [ 0.1713,  0.2239,  0.2537,  ...,  0.2190,  0.1808,  0.1404]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_by_name(\"dog\", n = 10, save_path=OUT_DIR / \"generation_dog.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
